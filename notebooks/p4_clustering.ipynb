{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Environment setup\n",
    "# -------------------------------------------------------------\n",
    "BASE_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Configuration\n",
    "# -------------------------------------------------------------\n",
    "from src.utils.config import load_config\n",
    "config = load_config(base_dir=BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "from dask_ml.decomposition import TruncatedSVD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding matematicos truncateSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# === Leer CSV ===\n",
    "individual_tensors = config[\"paths\"][\"tensors_convolution\"]\n",
    "data = dd.read_csv(individual_tensors)\n",
    "\n",
    "row_id = data.iloc[:, 0]                     # primera columna\n",
    "df_num = data.iloc[:, 1:].astype(float)      # num√©ricas\n",
    "\n",
    "print(\" to_dask_array \")\n",
    "X = df_num.to_dask_array(lengths=True)\n",
    "\n",
    "# === Escalado (Dask-ML) ===\n",
    "print(\" Escalado (Dask-ML) \")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === SVD sin cargar en memoria ===\n",
    "print(\" SVD \")\n",
    "n_components = 20\n",
    "tsvd = TruncatedSVD(n_components=n_components)\n",
    "X_reduced = tsvd.fit_transform(X_scaled)\n",
    "\n",
    "# Convertir resultado a Dask-DF sin computar en RAM\n",
    "print(\" to dask \")\n",
    "svd_cols = [f\"svd_{i}\" for i in range(n_components)]\n",
    "df_svd = dd.from_dask_array(X_reduced, columns=svd_cols)\n",
    "\n",
    "# Concatenar IDs + componentes\n",
    "print(\" concat \")\n",
    "result = dd.concat([\n",
    "    row_id.reset_index(drop=True),\n",
    "    df_svd.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# === Guardar sin computar en RAM ===\n",
    "print(\" Write \")\n",
    "tensors_svd = config[\"paths\"][\"tensors_svd\"]\n",
    "os.makedirs(os.path.dirname(tensors_svd), exist_ok=True)\n",
    "result.to_parquet(tensors_svd, write_index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"‚è∞ Start: {time.ctime(start_time)}\")\n",
    "print(f\"üèÅ End:   {time.ctime(end_time)}\")\n",
    "print(f\"‚è±Ô∏è Total: {end_time - start_time:.2f} sec ({(end_time - start_time)/60:.2f} min)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "client_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mcc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "amount_sol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "client_age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "client_gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "agency_ubigeo",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "debit_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns, pytz.FixedOffset(-300)]",
         "type": "unknown"
        },
        {
         "name": "mccg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "windows_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "turn_of_day",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9b8c15e3-823a-4ebe-856a-f664c19c94f2",
       "rows": [
        [
         "0",
         "85912210",
         "+cSS8MDLKuU=",
         "0",
         "183.5",
         "40",
         "F",
         "120101.0",
         "TC",
         "2016-10-01 23:19:17-05:00",
         "0",
         "2016-09-26",
         "5",
         "23",
         "3"
        ],
        [
         "1",
         "85912211",
         "+cSS8MDLKuU=",
         "0",
         "6.15",
         "40",
         "F",
         "120101.0",
         "TC",
         "2016-10-17 23:08:58-05:00",
         "0",
         "2016-10-17",
         "0",
         "23",
         "3"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>client_id</th>\n",
       "      <th>mcc</th>\n",
       "      <th>amount_sol</th>\n",
       "      <th>client_age</th>\n",
       "      <th>client_gender</th>\n",
       "      <th>agency_ubigeo</th>\n",
       "      <th>debit_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mccg</th>\n",
       "      <th>windows_time</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>turn_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85912210</td>\n",
       "      <td>+cSS8MDLKuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>183.50</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>120101.0</td>\n",
       "      <td>TC</td>\n",
       "      <td>2016-10-01 23:19:17-05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85912211</td>\n",
       "      <td>+cSS8MDLKuU=</td>\n",
       "      <td>0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>120101.0</td>\n",
       "      <td>TC</td>\n",
       "      <td>2016-10-17 23:08:58-05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-17</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     client_id  mcc  amount_sol  client_age client_gender  \\\n",
       "0  85912210  +cSS8MDLKuU=    0      183.50          40             F   \n",
       "1  85912211  +cSS8MDLKuU=    0        6.15          40             F   \n",
       "\n",
       "   agency_ubigeo debit_type                 timestamp  mccg windows_time  \\\n",
       "0       120101.0         TC 2016-10-01 23:19:17-05:00     0   2016-09-26   \n",
       "1       120101.0         TC 2016-10-17 23:08:58-05:00     0   2016-10-17   \n",
       "\n",
       "   day_of_week  hour  turn_of_day  \n",
       "0            5    23            3  \n",
       "1            0    23            3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| M√©todo de escalado      | Qu√© hace                                 | Preserva direcci√≥n | Ideal para Cosine | Ideal para Euclidean | Ideal para Manhattan (L1) | Ideal para Minkowski | Adecuado para K-Means | Comentarios clave |\n",
    "|--------------------------|-------------------------------------------|---------------------|--------------------|------------------------|---------------------------|------------------------|------------------------|--------------------|\n",
    "| **L2 Normalization**     | Normaliza cada vector a norma 1 (‚Äñx‚Äñ‚ÇÇ=1) | ‚úî S√≠               | ‚≠ê **S√≠** (equivalencia exacta) | ‚úî S√≠ (si magnitud no importa) | ‚ùå No (distorsiona L1) | ‚ùå No | ‚≠ê **S√≠ (cuando quieres imitar Cosine-KMeans)** | Convierte Euclidean en Cosine; ideal para embeddings y perfiles. |\n",
    "| **StandardScaler**       | Centra y escala cada feature (z-score)   | ‚ùå No              | ‚ùå **No** | ‚≠ê **S√≠** (distancia euclidiana cl√°sica) | ‚≠ê **S√≠** | ‚≠ê **S√≠** | ‚≠ê **S√≠** | Mantiene variancia comparable entre features; est√°ndar para ML tradicional. |\n",
    "| **MinMaxScaler**         | Escala cada feature a [0,1]              | ‚ùå No              | ‚ùå No | ‚≠ê S√≠ (cuando las escalas importan) | ‚≠ê S√≠ | ‚≠ê S√≠ | ‚≠ê S√≠ | Preserva relaciones relativas; √∫til en clustering basado en distancias mixtas. |\n",
    "| **RobustScaler**         | Escala usando medianas y IQR             | ‚ùå No              | ‚ùå No | ‚≠ê S√≠ (robusto a outliers) | ‚≠ê S√≠ | ‚≠ê S√≠ | ‚≠ê S√≠ | Excelente cuando hay outliers fuertes; no apto para coseno. |\n",
    "| **None (sin escala)**    | Deja los datos crudos                    | A veces            | ‚ùå No | ‚ùå No (si las escalas var√≠an entre features) | ‚ùå No | ‚ùå No | ‚ùå No | Solo √∫til si todas las features ya est√°n en la misma escala y sin outliers. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# individual_tensors = config[\"paths\"][\"tensors_convolution\"]\n",
    "tensors_svd = config[\"paths\"][\"tensors_svd\"]\n",
    "inpust_path = tensors_svd\n",
    "data = dd.read_parquet(inpust_path)\n",
    "data = data.repartition(npartitions=data.npartitions)\n",
    "\n",
    "id_col = \"row_id\"\n",
    "value_cols = [c for c in data.columns if c != id_col]\n",
    "\n",
    "X = data[value_cols].astype(float).to_dask_array(lengths=True)\n",
    "row_ids = data[id_col].to_dask_array(lengths=True).reshape(-1, 1)\n",
    "\n",
    "L1_norms = da.sum(da.abs(X), axis=1, keepdims=True)\n",
    "L1_norms = da.where(L1_norms == 0, 1, L1_norms)\n",
    "X_norm_L1 = X / L1_norms\n",
    "\n",
    "full_array = da.hstack([row_ids, X_norm_L1])\n",
    "df_norm_L1 = dd.from_dask_array(full_array, columns=[id_col] + value_cols)\n",
    "\n",
    "output_path_L1 = \"outputs/tensors_normalized_L1.parquet\"\n",
    "os.makedirs(os.path.dirname(tensors_svd), exist_ok=True)\n",
    "df_norm_L1.to_parquet(output_path_L1, write_index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"‚è∞ Start: {time.ctime(start_time)}\")\n",
    "print(f\"üèÅ End:   {time.ctime(end_time)}\")\n",
    "print(f\"‚è±Ô∏è Total: {end_time - start_time:.2f} sec ({(end_time - start_time)/60:.2f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# individual_tensors = config[\"paths\"][\"tensors_convolution\"]\n",
    "tensors_svd = config[\"paths\"][\"tensors_svd\"]\n",
    "inpust_path = tensors_svd\n",
    "data = dd.read_parquet(inpust_path)\n",
    "data = data.repartition(npartitions=data.npartitions)\n",
    "\n",
    "id_col = \"row_id\"\n",
    "value_cols = [c for c in data.columns if c != id_col]\n",
    "\n",
    "X = data[value_cols].astype(float).to_dask_array(lengths=True)\n",
    "row_ids = data[id_col].to_dask_array(lengths=True).reshape(-1, 1)\n",
    "\n",
    "L2_norms = da.linalg.norm(X, axis=1, keepdims=True)\n",
    "L2_norms = da.where(L2_norms == 0, 1, L2_norms)\n",
    "X_norm_L2 = X / L2_norms\n",
    "\n",
    "full_array = da.hstack([row_ids, X_norm_L2])\n",
    "df_norm_L2 = dd.from_dask_array(full_array, columns=[id_col] + value_cols)\n",
    "\n",
    "output_path_L2 = \"outputs/tensors_normalized_L2.parquet\"\n",
    "os.makedirs(os.path.dirname(tensors_svd), exist_ok=True)\n",
    "df_norm_L2.to_parquet(output_path_L2, write_index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"‚è∞ Start: {time.ctime(start_time)}\")\n",
    "print(f\"üèÅ End:   {time.ctime(end_time)}\")\n",
    "print(f\"‚è±Ô∏è Total: {end_time - start_time:.2f} sec ({(end_time - start_time)/60:.2f} min)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "consumer-3d-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
